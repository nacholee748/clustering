{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Point 1 \n",
    "\n",
    "a. In which cases might it be more useful to apply?\n",
    "    \n",
    "    Spectral clustering is characterized when data is not convex, when data is no linear and when we have high dimentional data\n",
    "\n",
    "b. What are the mathematical fundamentals of it?\n",
    "\n",
    "    Mathematical fundamentals for Spectral Clustering is based in the eigenvalues of the similarity matrix and the eigenvectors of laplaciane matrix A such is defined as similarity matrix\n",
    "\n",
    "c. What is the algorithm to compute it?\n",
    "\n",
    "    - Calculate laplaciane \n",
    "    - Calculate Eigenvectors correspondint to the k smallest eigenvalues of laplaciane\n",
    "    - Consider the matrix formed by the first k Eigenvectors considering the first row defining the futures for the first node\n",
    "    - Cluster the graph nodes based on these features\n",
    "\n",
    "d. Does it hold any relation to some of the concepts previously mentioned in class? Which, and how?\n",
    "\n",
    "    Respect to previous class for Spectral clustering is related with Eigenvectors, Eigenvalues and kmeans\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Point 2 \n",
    "\n",
    "a. In which cases might it be more useful to apply?\n",
    "\n",
    "    This method is useful when we need clustering for no convex data, when data has complex shape or for when has a lot of noise\n",
    "\n",
    "b. What are the mathematical fundamentals of it?\n",
    "\n",
    "    - Choose a data point randomly and find its neighborhood by searching for all the data points within the euler distance.\n",
    "    - If the chosen point is a core point, assign a new cluster label to it and expand the cluster by iteratively adding all the density-reachable points to the cluster.\n",
    "    - If the chosen point is a border point, assign it to the same cluster as its density-reachable core point.\n",
    "    - Repeat the process until all the data points have been assigned to a cluster or identified as noise.\n",
    "\n",
    "c. Is there any relation between DBSCAN and Spectral Clustering? If so, what is it?   \n",
    "\n",
    "    Both method allow clustering for no covex data but DBSCAN is a density-based clustering algorithm that identifies clusters based on the density of data points in the feature space, it can identify clusters of arbitrary shapes and can handle noise points effectively and Spectral Clustering is a graph-based clustering algorithm that uses the eigenvectors and eigenvalues of the affinity matrix to cluster the data points. It works by constructing a graph based on the similarity between the data points and then clustering the graph using spectral methods. S"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Point 3\n",
    "\n",
    "What is the elbow method in clustering? And which flaws does it pose to assess quality?\n",
    "\n",
    "    The elbow method could be useful  for determining the optimal number of clusters in some cases, but it is not a definitive method for evaluate quality, because this use the distances average and in some cases this could have problems for somes k"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Point 4\n",
    "\n",
    "Remember the unsupervised Python package you created in the previous unit?ðŸ˜€Itâ€™s time for an upgrade.\n",
    "\n",
    "a. Implement the k-means module using Python and Numpy\n",
    "\n",
    "b. Implement the k-medoids module using Python and Numpy\n",
    "\n",
    "c. Remember to keep consistency with Scikit-Learn API as high as possible\n",
    "\n",
    "    In the folder point4 is unsupervised_jim updated, for use it and run the library make following \n",
    "\n",
    "    \"\"\"\"\n",
    "        pip install requiriments.txt\n",
    "        cd point 4\n",
    "        pip install .\n",
    "\n",
    "    \"\"\"\"\n",
    "\n",
    "    The file test_unsupervised_jim_v2.ipynb has some tests with the news methods "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Point 5 \n",
    "\n",
    "a. Use the following code snippet to create scattered data X\n",
    "    \n",
    "    In the file /point5/point5.ipynb the snippet were loaded \n",
    "\n",
    "b. Plot the resulting dataset. How many clusters are there? How far are they from one another?\n",
    "\n",
    "    In the file /point5/point5.ipynb is implemented the code for plot the methods\n",
    "\n",
    "c. For both k-means and k-medoids (your implementations), calculate the silhouette plots and coefficients for each run, iterating K from 1 to 5 clusters.\n",
    "\n",
    "    In the file /point5/point5.ipynb is implemented the code for plot the methods\n",
    "\n",
    "d. What number of K got the best silhouette score? What can you say about the figures? Is this the expected result?\n",
    "\n",
    "    The best result is form k=4 and this is right result such "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Point 6\n",
    "\n",
    "a. Plot the different datasets in separate figures. What can you say about them?\n",
    "    In the file /point6/point6.ipynb are the graphs \n",
    "    \n",
    "\n",
    "b. Apply k-means, k-medoids, DBSCAN and Spectral Clustering from Scikit-Learn over each\n",
    "dataset and compare the results of each algorithm with respect to each dataset."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
